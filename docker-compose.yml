#version: '3.7'
#services:
#  postgres:
#    image: postgres
#    container_name: postgres
#    environment:
#      POSTGRES_USER: airflow
#      POSTGRES_PASSWORD: airflow
#      POSTGRES_DB: airflow
#    ports:
#      - "5432:5432"
#    volumes:
#      - postgres_data:/var/lib/postgresql/data
#
#  airflow-webserver:
#    image: apache/airflow
#    container_name: airflow-webserver
#    environment:
#      AIRFLOW__CORE__EXECUTOR: LocalExecutor
#      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
#      AIRFLOW__CORE__FERNET_KEY: JAay-SgKnAkUJGuWS48a0ngMqXSZEDR8IbIVyrHUKrc=
#      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
#      _AIRFLOW__WEBSERVER__DEFAULT_UI_USER: admin
#      _AIRFLOW__WEBSERVER__DEFAULT_UI_PASSWORD: admin
#    volumes:
#      - ./dags:/opt/airflow/dags
#      - ./logs:/opt/airflow/logs
#      - ./plugins:/opt/airflow/plugins
#    ports:
#      - "8080:8080"
#    depends_on:
#      - postgres
#    command: ["webserver"]
#
#  airflow-scheduler:
#    image: apache/airflow
#    container_name: airflow-scheduler
#    environment:
#      AIRFLOW__CORE__EXECUTOR: LocalExecutor
#      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
#      AIRFLOW__CORE__FERNET_KEY: JAay-SgKnAkUJGuWS48a0ngMqXSZEDR8IbIVyrHUKrc=
#      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
#    volumes:
#      - ./dags:/opt/airflow/dags
#      - ./logs:/opt/airflow/logs
#      - ./plugins:/opt/airflow/plugins
#    depends_on:
#      - postgres
#    command: ["scheduler"]
#
#  airflow-init:
#    image: apache/airflow
#    container_name: airflow-init
#    command: version
#    environment:
#      _AIRFLOW_DB_UPGRADE: 'true'
#      _AIRFLOW_WWW_USER_CREATE: 'true'
#      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
#      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
#
#
#volumes:
#  postgres_data:
#
####################################################################
#version: '2'
#services:
#  postgresql:
#    image: 'bitnami/postgresql:latest'
#    environment:
#      - POSTGRESQL_DATABASE=bitnami_airflow
#      - POSTGRESQL_USERNAME=bn_airflow
#      - POSTGRESQL_PASSWORD=bitnami1
#    volumes:
#      - /path/to/postgresql-persistence:/bitnami
#  redis:
#    image: 'bitnami/redis:latest'
#    environment:
#      - ALLOW_EMPTY_PASSWORD=yes
#    volumes:
#      - /path/to/redis-persistence:/bitnami
#  airflow-worker:
#    image: bitnami/airflow-worker:latest
#    environment:
#      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
#      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
#      - AIRFLOW_EXECUTOR=CeleryExecutor
#      - AIRFLOW_DATABASE_NAME=bitnami_airflow
#      - AIRFLOW_DATABASE_USERNAME=bn_airflow
#      - AIRFLOW_DATABASE_PASSWORD=bitnami1
#      - AIRFLOW_LOAD_EXAMPLES=yes
#  airflow-scheduler:
#    image: bitnami/airflow-scheduler:latest
#    environment:
#      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
#      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
#      - AIRFLOW_EXECUTOR=CeleryExecutor
#      - AIRFLOW_DATABASE_NAME=bitnami_airflow
#      - AIRFLOW_DATABASE_USERNAME=bn_airflow
#      - AIRFLOW_DATABASE_PASSWORD=bitnami1
#      - AIRFLOW_LOAD_EXAMPLES=yes
#  airflow:
#    image: bitnami/airflow:latest
#    environment:
#      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
#      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
#      - AIRFLOW_EXECUTOR=CeleryExecutor
#      - AIRFLOW_DATABASE_NAME=bitnami_airflow
#      - AIRFLOW_DATABASE_USERNAME=bn_airflow
#      - AIRFLOW_DATABASE_PASSWORD=bitnami1
#      - AIRFLOW_PASSWORD=bitnami123
#      - AIRFLOW_USERNAME=user
#      - AIRFLOW_EMAIL=user@example.com
#    ports:
#      - '8080:8080'


#version: '3'
#x-airflow-common:
#  &airflow-common
#  image: apache/airflow:2.0.0
#  environment:
#    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
#    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
#    - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
#    - AIRFLOW__CORE__LOAD_EXAMPLES=False
#    - AIRFLOW__CORE__LOGGING_LEVEL=INFO
#  volumes:
#    - ./dags:/opt/airflow/dags
#    - ./airflow-data/logs:/opt/airflow/logs
#    - ./airflow-data/plugins:/opt/airflow/plugins
#    - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
#  depends_on:
#    - postgres
#
#services:
#  postgres:
#    image: postgres:12
#    environment:
#      - POSTGRES_USER=postgres
#      - POSTGRES_PASSWORD=postgres
#      - POSTGRES_DB=airflow
#      - POSTGRES_PORT=5432
#    ports:
#      - "5432:5432"
#
#  airflow-init:
#    << : *airflow-common
#    container_name: airflow_init
#    entrypoint: /bin/bash
#    command:
#      - -c
#      - airflow users list || ( airflow db init &&
#        airflow users create
#          --role Admin
#          --username airflow
#          --password airflow
#          --email airflow@airflow.com
#          --firstname airflow
#          --lastname airflow )
#    restart: on-failure
#
#  airflow-webserver:
#    << : *airflow-common
#    command: airflow webserver
#    ports:
#      - '8080:8080'
#    container_name: airflow_webserver
#    restart: always
#
#  airflow-scheduler:
#    << : *airflow-common
#    command: airflow scheduler
#    container_name: airflow_scheduler
#    restart: always


version: '3.8'
services:
    postgres:
        image: postgres
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
    scheduler:
        build:
            context: .
            dockerfile: Dockerfile
        command: scheduler
        deploy:
            restart_policy:
                condition: on-failure
        depends_on:
            - postgres
        env_file:
            - .env
        environment:
            - PYTHONPATH=/opt/airflow/scripts:/opt/airflow/dags
        volumes:
            - ./dags:/opt/airflow/dags
            - ./logs:/opt/airflow/logs
            - ./scripts:/opt/airflow/scripts
            - ./requirements.txt:/requirements.txt
    webserver:
        build:
            context: .
            dockerfile: Dockerfile
        entrypoint: ./scripts/entrypoint.sh
        deploy:
            restart_policy:
                condition: on-failure
        depends_on:
            - postgres
            - scheduler
        env_file:
            - .env
        environment:
            - PYTHONPATH=/opt/airflow/scripts:/opt/airflow/dags
        volumes:
            - ./dags:/opt/airflow/dags
            - ./logs:/opt/airflow/logs
            - ./scripts:/opt/airflow/scripts
            - ./requirements.txt:/requirements.txt
        ports:
            - "8080:8080"